<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Assume Wisely - Analytics Engineering]]></title><description><![CDATA[Analytics Engineering and BI development insights.]]></description><link>https://assumewisely.com</link><generator>GatsbyJS</generator><lastBuildDate>Thu, 27 Nov 2025 20:30:54 GMT</lastBuildDate><item><title><![CDATA[Snowflake DateDiff Business Days: How do I exclude weekends?]]></title><description><![CDATA[
A common ask in analytics engineering is to return the working days between two dates not the calendar days.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/snowflake-datediff-business-days</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/snowflake-datediff-business-days</guid><pubDate>Mon, 24 Jul 2023 00:00:00 GMT</pubDate><content:encoded>
This is the code leverages Snowflake DateDiff to calculate business days.

`select`  
`DATEDIFF(&apos;day&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) + 1`  
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, DATEADD(&apos;day&apos;, 1, &apos;2022-07-14&apos;))`  
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) as working_days`  
`;`
    
It looks a little wonky. I&apos;ll break it down into steps. Basically we are calculating three values: a, b, &amp; c. Then we are subtracting b &amp; c from a: a-b-c. 

## DateDiff Naive Count of Days
This first expression naively counts days between start and end. The +1 means the end date is included as part of the count.

`DATEDIFF(&apos;day&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) + 1`

## Subtract Saturdays          
This second expression counts Saturdays. There can never be fewer Saturdays than Sundays in a given range because Snowflake starts the week on Monday and Sunday is after Saturday. We want to check whether the last day in the range is a Saturday. This expression checks by calculating how many weeks there are in this range if the last day is forwarded by one day.

For example, if the last day is a Friday, then it moves to Saturday, and that partial week doesn&apos;t count towards our total because DATEDIFF(&apos;week&apos;, ...) only counts fully completed weeks. 

However, if the last day is a Saturday, then it gets bumped to a Sunday, and this count will increase.

`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, DATEADD(&apos;day&apos;, 1, &apos;2022-07-14&apos;))`

## Subtract Sundays
This third piece counts the number of fully completed weeks, which will be the same as the number of Sundays in that range (there is one Sunday per week).        
        
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;)`

## Putting it all together with DateDiff to get Business Days
Putting all the expressions together, we subtract the Saturday count and Sunday count from the first naive count to calculate the number of weekdays elapsed in the time range.

`select`  
`DATEDIFF(&apos;day&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) + 1`  
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, DATEADD(&apos;day&apos;, 1, &apos;2022-07-14&apos;))`  
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) as working_days`  
`;`

This pattern can be adjusted to accommodate different week start days.

## Plus 5 Business Days

As a follow up to the same idea I had to deploy logic that returned the date that is 5 business days from any given calendar date. It&apos;s pretty straightforward once you wrap your head around it. Including examples for plus 4 business days as well.

`,  case`  
`     when day_name = &apos;Sunday&apos; then dateadd(&apos;day&apos;,4,date)`  
`     when day_name = &apos;Monday&apos; then dateadd(&apos;day&apos;,4,date)`  
`     when day_name = &apos;Saturday&apos; then dateadd(&apos;day&apos;,5,date)`  
`     else dateadd(&apos;day&apos;,6,date)`  
`   end as plus_4_business_days` 

`, case`  
`when day_name = &apos;Sunday&apos; then dateadd(&apos;day&apos;,5,date)`  
`when day_name = &apos;Saturday&apos; then dateadd(&apos;day&apos;,6,date)`  
`else dateadd(&apos;day&apos;,7,date)`  
`end as plus_5_business_days`

### Resources:

[Snowflake Docs](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#label-calendar-weeks-weekdays)

</content:encoded></item><item><title><![CDATA[The Spaghetti]]></title><description><![CDATA[
Suddenly, I find myself wearing the expert hat, not because I earned it, but because everyone who knows better is gone.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/business-dimensional-modeling</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/business-dimensional-modeling</guid><pubDate>Wed, 21 Jun 2023 00:00:00 GMT</pubDate><content:encoded>
Serge leans back, a mischievous grin playing on his face, and says, &quot;You know, Max, there was a time when I encountered a metric so absurd, I had an existential crisis. It’s all BS. Why even bother? I questioned the point of it all, ya know?&quot; His words pique my curiosity, and I lean in. His eye twinkles, Serge begins his story, transporting me to a world where data anomalies run rampant and the quest for truth takes an unexpected turn.

Serge begins his story. This is Part II of, [I Smell Color](http://color.assumewisely.com). You can start at the begining, [Confessions of Analytics Professonals](/thoughts/confessions-analytics-professionals).

What stays with me is the buzz in the air. The whole place is on a caffeine high, buzzing with excitement and innovation. Boy do I feel like the small fish in a big pond. The logo on the wall is unmistakable. At the time it still felt surreal to work as part of an analytics department, let alone there. Perks galore. All-you-can-eat snacks. Gourmet coffee. They&apos;ve got it all covered. Nothing gets my analytical mind going like topping off a cup of joe.

I sink down into the loving embrace of my ergonomic chair. Desks so long it could be the hood of a Dodge Viper. Natural light streams in through floor to ceiling windows. This is all pre-pandemic mind you, work from home wasn’t a thing.

It&apos;s not just about the creature comforts. This company knows how to inject some serious fun into the mix. Picture this—life-sized foosball. Yeah, you heard me. It&apos;s like regular foosball, but each player is an actual person attached to other actual people with a long pole, jiving and juking, trying to score a goal. It&apos;s like synchronized swimming, but with less water and more high fives. Teamwork makes the dream work, right?

Then there is my boss—a real wizard when it comes to data. Slicing and dicing numbers like a chef with a sharp knife, deep understanding of the company&apos;s operations. Expertise and leadership off the charts. He is our North Star, guiding us through the vast abyss of data. And trust me, in this field, you need someone with a map and a compass, &apos;cause it&apos;s easy to get lost in a sea of ones and zeros. 

To be honest I feel pretty dumb, but as the saying goes if you’re the smartest person in the room you&apos;re in the wrong room. I must be in the right room ‘cause I’m learning a lot. I’m a kid in a candy store, except for nerds: a sage in the stacks; a brain in the books.

And then in an instant everything changes.

One minute, I&apos;m part of a talented analytics team at a  marquee tech company, and the next, I&apos;m thrust into the spotlight as my boss and several other leaders abandon ship, irreconcilable differences with management. Talk about being caught in the whirlwind. Suddenly, I find myself wearing the expert hat, not because I earned it, but because everyone who knows better is gone. It&apos;s like I&apos;m the captain of a ship with no crew and a map full of uncharted waters.

Now, let me tell you about the state of our data. At the time, we didn’t know. That was the issue. It was a black box. Our data model was opaque with logic scattered all across the data stack. As we pick around the edges a picture starts to form. Imagine a dense, thorny briar patch, each thicket representing a tangled mess of information. That&apos;s how I see it—unruly, interlacing, and chaotic. Management has a different take. They call it &quot;spaghetti,&quot; a swirling plate of tangled noodles. It’s actually not far from the truth. Each report fed directly from the source, the logic for each was self contained and sometimes borrowed.

You want an example of this spaghetti madness? Here&apos;s a good one. We have seventeen different conversion metrics. Each of them has their own specific meaning and purpose, valid in their own little worlds. But when you try to make sense of it across the business, you get seventeen flavors of conversion. Imagine Baskin Robins with 31 flavors all named, Vanilla. What&apos;s the point? We are looking for clarity, and finding a confusing conundrum of identical-sounding KPIs.

But wait, it gets better. Throughout our dataset, we stumble upon conflicting definitions for dimensions. It&apos;s like having a dictionary that contradicts itself. The same word with two definitions and you&apos;re left scratching your head, one definition says &quot;up,&quot; the other says &quot;down.&quot; Trying to make sense of such discordant definitions is solving a puzzle with mismatched pieces. We found ourselves in a precarious situation.

I’m looking at this spaghetti mess, the road ahead won&apos;t be easy. We need to find a way to bring order to the chaos, to streamline our metrics, and align our definitions. But how?

So, here I am, the accidental expert, ready to untangle the spaghetti. Because if there&apos;s one thing I&apos;ve learned, it&apos;s that sometimes, even the most twisted paths can lead to surprising discoveries. And who knows, maybe along the way, we&apos;ll find a hidden meatball or two. 

That singular thought keeps me going. Find the meatball. There is gold in these hills, start digging.

This is Part II of my new book, [I smell color.](http://color.assumewisely.com). If you made it to this point, consider subscribing. You can sign up [here](http://color.assumewisely.com).

[![I smell color.](./media/ads/i_smell_color_ad_01.png)](http://color.assumewisely.com)

## How did we get here?

Alright, buckle up ‘cause now we are getting into the thick of it. Have you heard of CRISP-DM, the Cross-Industry Standard Process for Data Mining? It&apos;s like a roadmap to navigating data analysis. Someone had the bright idea to come up with an acronym for wildly intuitive common sense. 

- Start with understanding the business.
- Figure out what questions you want to answer.
- Dive into the data. 
- Unleash your analytical skills, exploring the data like a curious detective. 
- Once you&apos;ve uncovered some insights, fine-tune your models. 
- Finally, you present your findings. 

Now, grab a plate.

Imagine your little world of analytics as a massive bowl of spaghetti, with each noodle representing a report. Each noodle is cooked up using its unique recipe, applying CRISP-DM. It&apos;s directly modeled from the source data, seasoned based on specific questions and business objectives. You take another noodle, different report, cooked using the same CRISP-DM process but different questions means different seasoning. Each noodle, each report, has its own spin on the process, like adding various toppings or spices. Some noodles might be al dente, perfectly capturing the essence of the data, while others may be a bit overcooked, losing some of that data goodness. Mind you, that’s on purpose! Behold the spaghetti bowl of analytics! Hundreds of unique reports, each offering a different perspective, all tangled together by the common thread of the CRISP-DM approach. So, grab your fork and start twirling, because in this delicious world of data, every noodle tells its own story.

That’s a pretty good illustration of how we got to this point. For onesie-twosie analysis CRISP-DM works. But it doesn’t scale.

The more seasoned (no pun intended) analysts want to do away with data modeling all together. They want to join everything to everything. They envision it would look like a kind of mosaic. Each tile is a data source, and when assembled forms a breathtaking masterpiece . . . 

in theory.

In reality it’s more like a patchwork quilt with bald spots and gaps. This monolithic wide sparse table of data is large. It’s slow. And it joins everything to everything creating dependencies and points of failure across reports that for all practical purposes aren’t related.

So where CRISP-DM is too much, this mosaic model is not enough. The problem with CRISP-DM and the monolith mosaic is that each approaches data as random bits and pieces. But we don’t want to model the data, we want to model the lifeblood of business—transactions, customers, products, and everything in between. We have our source data in one hand and the reports we want to create in the other. But what we don’t have is a winning strategy to get from one hand to the other. 

## The Solution

The Goldilocks model is business dimensional modeling. Business dimensional modeling takes these vital concepts and arranges them in a way that reflects the reality of the business and facilitates analysis and decision-making. 

In the beginning we didn’t know what to call it. So we called our efforts lego blocks. You can think of  business dimensional modeling as creating the building blocks of reporting. It&apos;s about organizing the diverse elements of a business into pieces that can be interlocked and unlocked in novel and unique ways while still maintaining a consistent foundational definition. For example, a kid can use a cardboard box as a boat, a table, or even a fort but we can still agree it’s a cardboard box. In the same way an idea can connect to another idea or concept along common dimensions and metrics, forming a cohesive and comprehensive view of the business. It represents how we think about the business because it models what we think about the business and ties in the relevant data.

(At this point Serge grabs a napkin, scribbling on it before handing it to me.)

![the napkin model](./media/content/business_dimensional_modeling_napkin.png)

Bazinga!

In contrast the CRISP-DM and mosaic models are largely dependent on their sources to define the structure. With all the different sources you lose cohesion. That is how it all gets bogged down.

Nailing down the problem was the first step. Wrapping our heads around business dimensional modeling was the next step. This is when we began taking our first steps away from working as analysts and started seeing ourselves as analytics engineers. At that point we still hadn’t heard the term analytics engineer, even though that is what we were doing. It wasn’t until we adopted DBT into our data stack that everything really became clear.

DBT, or Data Build Tool, is our magic wand for transforming and modeling data. It&apos;s a platform that allows us to wrangle, shape, and organize the data to model the business. With the help of DBT, we can implement the principle of separation of concerns to organize and manage our transformations.

Separation of concerns is a principle in software development that advocates for breaking down a system into distinct and independent parts, with each part responsible for a specific aspect of functionality. Separation of concerns means we break down the transformation process into smaller, manageable chunks. Each transformation focuses on a specific aspect or concern, allowing us to maintain clarity and avoid tangled spaghetti code. By modularizing our transformations, we enhance reusability, maintainability, and collaboration within our team. The goal is to ensure that each component focuses on a single concern and is decoupled from other parts of the system.

One of the key tools DBT offers is Directed Acyclic Graphs (DAGs), maps that illustrate the path our data takes from source to the final destination. These maps illustrate the data transformation arc. We start with the source data, which is often messy and unrefined. We use DBT to perform a series of transformations, taking the data on a journey from a multiverse of chaos to a world of understanding. We clean the data, apply business rules, and ensure the data conforms to our business dimensional models. These models or core business logic serve as the foundation for reporting. 

As we progress along the transformation arc, our data starts to take shape. We can build data marts for specific business areas or functions. These data marts are built with our business dimensional models, ensuring that the data is structured in a way that supports efficient analysis and reporting. 

Now, here&apos;s the exciting part—reporting on top of our business dimensional models. With the data now organized and modeled in a meaningful way, we can unlock valuable insights and empower decision-makers with actionable information . . . at scale. We can slice and dice the data, apply filters, and drill down into specific dimensions to understand trends, patterns, and outliers. The reports we develop are consistent because they come from a single source of truth, the business dimensional model.

But wait, there&apos;s more! DBT doesn&apos;t stop at just transforming and modeling data. It also provides features for data testing, documentation, and version control. We can validate the accuracy and integrity of our transformed data, document the entire process, and ensure that changes are tracked and auditable. 

And then there is Jinja. I got started with DBT for the documentation, but I stayed for the Jinja. My interest in DBT began with a desire for automated documentation. Jinja sold it. I discovered Jinja, and my SQL game is forever changed. I really like using Jinja in my SQL. 

At it&apos;s core, DBT aligns three technologies to deliver knowledge better: SQL, YAML, &amp; Jinja. You can do a lot with just SQL and YAML. Adding in Jinja makes SQL feel a lot more like traditional development. I kinda missed that. It&apos;s like seeing an old friend that you really liked but haven&apos;t seen for a while.

It’s next level.

## A Better place

And that my friend, brings us to today. We have come a long way. We are in a better place—a place where the mystic single source of truth is no longer an elusive dream but a tangible reality within our data stack. A crystal-clear path to coherence.

Not really. But you-know we’re getting there. Much closer for sure. 

The backbone that stands it all up is our collection of business dimensional models. They lay the foundation for all the insights we unravel. They are the sources of truth and, and, AND we can trace &apos;em back to wherever the hell they came from. We turned a tangled mess of spaghetti into a neat, organized stack of . . . i don’t know . . . it’s a lasagna. We&apos;ve brought order to the chaos, my friend. That’s the real freakin’ deal.

Each report we build is on a solid source of truth. What&apos;s beautiful about it? Each one has the freedom to frame those truths in its own way. No cookie-cutter nonsense here. We bring a fresh perspective to each report, the freakin&apos; art of data storytelling, my friend.

&lt;br&gt;&lt;/br&gt;
&lt;br&gt;&lt;/br&gt;

“Damn,” is all I can say.

## Later That Night

Later that night I’m at home, my macbook open to a blank screen. I jot down the key takeaways from my conversation with Serge. I’m still laughing about “data lasagna”. Serge is a character. I reflect on the importance of good friends, people who know what you are going through and a healthy dose of humor with your troubles. Armed with newfound insights (and caffeine) I jot down some notes:

As an analyst I win when I can:
 - provide reliable metrics and KPIs
 - answer my bosses (stupid) questions
 - demonstrate competence and confidence in the data

The success of my work relies on the underlying data model. When it comes to modeling I have three options:
 - CRISP-DM (spaghetti)
 - Wide Table (threadbare patchwork quilt)
 - Business Dimensional Modeling (the only scalable alternative - lasagna)

Business Dimensional Modeling helps me win as an analyst because:
 - core business objects create order for how we think about the stuff of our business
 - data lineage shows the transformational arc of the data
 - separation of concerns helps everyone see the steps in the transformation

As an analyst I don’t want to be beholden to my data sources to organize my thinking for me. I don’t want to reinvent the wheel from source data every time I need to create a new report. I want subject matter expertise and domain knowledge to frame the structure of how I think. I insert the data into that framework to inform decisions, tactics, opportunities, etc. If and when sh*t hits the fan, I can look to the DAGs to troubleshoot.

I think I’m picking up what Serge was putting down. I&apos;m excited to share what I&apos;ve learned at work. Tomorrow. Today&apos;s been a full day.


## Seriously, if you made it to this point, 

Do me a solid and subscribe. It&apos;s the only way I see if this is adding value. You can sign up [here](http://color.assumewisely.com).

I&apos;ll shoot you a short email when the next part drops.

[![I smell color.](./media/ads/i_smell_color_ad_01.png)](http://color.assumewisely.com)</content:encoded></item><item><title><![CDATA[(CAP) Confessions of Analytics Professionals]]></title><description><![CDATA[ I sit in a brightly lit room, adorned with charts and graphs, I can't help but feel a sense of relief mixed with trepidation. This isn't your typical support group, but rather Confessions of Analytics Practitioners (C.A.P.)—the gathering place for data analysts like me who are trapped, ensnared in a conflict of metrics. It used to be Mistaken Metrics Anonymous but the MMA shorthand drew the wrong crowd.  ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/confessions-analytics-professionals</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/confessions-analytics-professionals</guid><pubDate>Mon, 05 Jun 2023 00:00:00 GMT</pubDate><content:encoded>Hi, my name is Max, and I am mistaken. I sit in a brightly lit room, adorned with charts and graphs, I can&apos;t help but feel a sense of relief mixed with trepidation. This isn&apos;t your typical support group, but rather Confessions of Analytics Practitioners (C.A.P.)—the gathering place for data analysts like me who are trapped, ensnared in a conflict of metrics. It used to be Mistaken Metrics Anonymous but the MMA shorthand drew the wrong crowd. One too many nerds were forced to tap out and the name changed. Little do I know that this humble meeting would become the turning point in my journey, where I will find solace, humor, and the courage to face the challenge of deciphering the truth hidden within a tangle of numbers.

My story isn’t that unique. In the fast-paced world of data analytics, I find myself tangled in a web of confusion. I’m tasked with delivering reliable key performance indicators (KPIs) and metrics to the boss, Stacie Dime, a decisive leader who relies on me both for crucial business decisions as well as  inane questions. The work ahead, behind, and all around is strewn with challenges and conflicting values. 

Day in and day out, I scour reports hoping to find the needle of truth in the haystack of numbers. The more I search, the more I feel trapped in a data-driven version of &quot;Where&apos;s Waldo?&quot; The sheer volume of information is overwhelming. I chase from minut detail to minut detail. I never seem to find the truth. I hate the feeling that I&apos;m wrong. That feeling, I tell the group, is where my story begins.

[![I smell color.](./media/ads/i_smell_color_ad_01.png)](http://color.assumewisely.com)

## Stacie Dime

“We’re f*cked!”

The words reverberate in my mind. Stacie Dime repeats them again and again. How many times can she utter that phrase before deciding to fire me? I am about to find out. It’s even worse when your boss . . . is also the owner. Owners are always worse. It’s more personal for them. 

I poured my heart and soul into . . . hours of effort condensed into a single document. Stacie dismisses it with a fleeting glance. The numbers, apparently, are all wrong.

The weight of those two words hung heavy in the air. If our reporting lacks reliability, the business suffers. The message hit hard. I glanced around the room, Harper seems very focused on not making eye contact. Everyone else looks away.

If we can’t have reliable reporting, we’re f*cked. Message received.

I recount the countless hours spent poring over reports, meticulously coding my SQL, and striving for perfect formatting. I believed I had cracked the code. That of course was before Stacie saw it.

I finish my story. I look across the room to see empathetic nods and knowing smiles. I&apos;m not alone. 

I exhale. 

I feel a little better.

## Serge Sookram

A tantalizing scent wafts through the air, calling for an end to the meeting. It&apos;s food time. The food is usually pretty good and today—it’s from a New York deli food truck. I can&apos;t resist a juicy pastrami sandwich. It’s piled high with dill pickles and a bag of salt-n-vinegar chips. As I take a big bite, a voice from beside me exclaims, &quot;Nice choice! I&apos;m Serge, an analytics engineer with an appetite for everything that&apos;ll kill me: fast food, fast cars, &amp; fast women.” 

We laugh.

“I feel your pain,” Serge empathizes. “Truth be told, I&apos;m sure my analyst said as much. I know I said it plenty, in part that drove me into analytics engineering. I subscribe to the Papa Johns school of cooking: better ingredients, better pizza. Same goes for working with data. Garbage in. Garbage out. Better data means better insights.”

“Said?” I question. “Your analyst said as much. You mean as in now they don’t?”

“I’d like to think so.” Serge leans back, a mischievous grin playing on his face, and says, &quot;You know, Max, there was a time when I encountered a metric so absurd, I had an existential crisis. It’s all BS. Why even bother? I questioned the point of it all, ya know?&quot; His words pique my curiosity, and I lean in. His eye twinkles, Serge begins his story, transporting me to a world where data anomalies run rampant and the quest for truth takes an unexpected turn.

Serge begins his story.

### Serge’s story

If you made it to this point, consider subscribing. You can sign up [here](http://color.assumewisely.com).

You can read the next part [here](/thoughts/business-dimensional-modeling).

[![I smell color.](./media/ads/i_smell_color_ad_01.png)](http://color.assumewisely.com)



</content:encoded></item><item><title><![CDATA[Streamlit and Snowflake for Data-Driven Decision Making]]></title><description><![CDATA[ An Introduction for Junior Developers on Leveraging Streamlit and Snowflake for Business Intelligence (BI) Development and Data-Driven Deployment. ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/streamlit</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/streamlit</guid><pubDate>Wed, 12 Apr 2023 00:00:00 GMT</pubDate><content:encoded>Are you a junior developer or data analyst looking to level up your skills in business intelligence (BI) development and data-driven deployment? Today I came across Streamlit. It boasts the promise of a powerful open source community with the additional benefit that Snowflake just acquired it for $800M. Basically Streamlit sits on top of Snowflake to condense your front end development for data visualization. It&apos;s a super lightweight alternative to Flask or Django. (Read: much shorter learning curve.) 

[![Tired of Hearing You Need More Experience](./media/ads/sad_chick.png)](http://experiencebook.assumewisely.com)

Streamlit is a Python-based open-source library that allows you to easily create interactive web applications for data visualization and analysis. Snowflake, is a cloud-based data warehousing platform that provides scalable and secure storage and analytics capabilities for handling large amounts of data. Streamlit does a lot of heavy lifting for front end development. Snowflake is really like having a data engineer in your pocket. Together, Streamlit and Snowflake can be a game-changer for BI development and data-driven deployment. As a BI developer my primary use case is within the Snowflake app. From what I&apos;ve seen it seems like Snowflake has put together a solid offering there.

But, I also want to be able to visualize public and open source data here at Assume Wisely. I can use React, but there are challenges. The main challenge is paying to host the apps in Heroku and integrating the apps into the framework of my static Gatsby React site. Looking at this video, it seems like I can do just that with no overhead.

[![Deploying Your App to StreamLit](https://img.youtube.com/vi/HKoOBiAaHGg/hqdefault.jpg)](https://youtu.be/HKoOBiAaHGg)

I guess I have a new toy to play with. 

I will say, this is great for rapid prototyping of a report or presentation. But as far as exploring data to find insights I would use a tool like Tableau or Looker.

</content:encoded></item><item><title><![CDATA[SEO Optimization with React.js]]></title><description><![CDATA[
Google actually publishes a handy search engine optimization or SEO starter guide through the google search central. We're going to go through this and go over the various pieces of how a site should be built and optimized. In terms of SEO There are three big areas of focus. I'll focus on all three parts of this SEO triangle.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/seo-with-react</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/seo-with-react</guid><pubDate>Thu, 02 Jun 2022 00:00:00 GMT</pubDate><content:encoded>

Today we&apos;re talking about SEO or search engine optimization. In terms of SEO There are three big areas of focus. 
The first is page content.  How SEO relates to the content on each individual page of your website.
The second section i&apos;m going to focus on is page structure. How the page is built.
The third section i&apos;m going to focus on is site structure.
I&apos;ll focus on all three characteristics as part of this SEO triangle.

![SEO Triangle](./media/content/seo_triangle.png) 

Google actually publishes a [handy search engine optimization or SEO starter guide](https://developers.google.com/search/docs/beginner/seo-starter-guide)
 through the google search central. We&apos;re going to go through this and go over the various pieces of how a site should be built
and optimized. I will also touch on the technology I use to publish search engine optimized content.

`I build using Gatsby a react framework. For SEO i use Helmet. The react helmet allows me to build SEO
into my content programatically, saving me from having to do it all manually.`

## How can i structure content? The first piece the SEO triangle.

You&apos;ll notice up at the top of the browser the tab has a page title. The left side is the specific name of the page and the right side is the name of the
site. This is best practice SEO strategy. Helmet allows me to do this programatically. This is big.
If I reference Google Search Central in the SEO Guide it says, 

- Create unique accurate page titles.

The title tag inside the head is where you&apos;re going to find the title of the page. Google goes on to say,

- Create good titles and snippets in search results.
- The best practice is to choose a title that reads naturally and effectively that communicates the topic of the page&apos;s content.
- avoid single title across all your pages or large groups

What you don&apos;t want to do is list each page with the same title. With these tools I can do this at scale.
The result is specific title names for each page of a site. 


Google is also looking for some sort of description. Google recommends,

- Use the description meta tag

The description tag is meta description with content. What merits a good description? 
Essentially, about 160 characters inside your page to sum up what the page is about.

In addition content should include titles, not just the page title but, the h1 title tag and relevant
paragraph h2s and h3s. I always build my sites when possible with only one h1 tag. That is like a chapter
title of a book. Chapters don&apos;t have two titles. They only have one.
My recommendation is always having a single h1 on a page.

Now let&apos;s swich gears to page structure.

## The fastest front end for the modern web

Why  care about fastest?  Because Google cares about fastest.
Google has an entire page called developers.google.com/speed. 
Their goal is to make the web faster.
This is a great tool to use to analyze any website to see how fast or how slow the page loads.
The great part about this is that most sites built on Gatsby hit really high speeds. 
Older sites (*cough WordPress*) basically run much slower.
The reason for that is Gatsby&apos;s built on a fast framework.
The site is already pre-built for speed.
What i really am a huge proponent of Gatsby is the gatsby-image handling.

The biggest load time of any website is going to be images on your page.
Videos load differently because they&apos;re going to be loading through iframes and through Youtube, Vimeo.
Pictures take up load time.
The great part about Gatsby is it helps optimize that speed for your web page so the user is
not waiting forever to see your page.

Gatsby generates webp images. Not jpeg or png. Now what the heck is a webp format?
It&apos;s is actually a new image format for the web developed by Google.
Google developed its own image format that makes pictures smaller, which of
course Google wants, to build a faster web.
So even if my source files are jpeg and png, i can convert them to webp at scale, lowering the file size
and making for the fastest front end on the modern web.

Your site loads faster.

## The last piece, site structure.

Simple URLs convey content information. URLs like the
following can be confusing and unfriendly:

- brandonsbaseballcards.com/folder1/224475/x2/55843.html

As you can see here Google likes structures that convey information:

-  brandonsbaseballcards.com/article/ten-rarest-cards.html

I can gnerate this dynamically using slugs. The slugs take into account my
folder structure. I don&apos;t just name something &apos;untitled&apos;. I am purposeful and aware in naming pieces
of work with file names that relate to the site structure. 

This is the technical side of SEO. There is also the strategic dimension that deals with language, word choice as well as reasearch into the market for information.</content:encoded></item><item><title><![CDATA[Tailwind CSS]]></title><description><![CDATA[ Notes on using Tailwind CSS that I find useful and want to keep handy.  ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/tailwind-css</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/tailwind-css</guid><pubDate>Sun, 22 May 2022 00:00:00 GMT</pubDate><content:encoded>
## Responsive Design
[Responsive Design Docs](https://tailwindcss.com/docs/responsive-design)
: Breakpoint Prefixes: sm, md, lg, xl, 2xl

## The Holy Grail
Typical (best practice) web page design practice. A header and footer sandwich the main content of the page. 
Often the main content will have sidebars that we can refer to as nav on the left, and aside on the right.
The areas of a webpage are header, nav, main, aside, &amp; footer.

## Talking intelligently about code

A &quot;CSS Rule&quot; is defined as:
{/* ![CSS Rule](./media/content/css_rule.png) */}

Collectively a property and its value are called a declaration.

## Difference between rem &amp; em:
    - em unit allows setting the font size of an element relative to the font size of its parent
    - rem is based upon the font-size value of the root element, which is the `&lt;html&gt;` element

## Page Layout

[Order](https://tailwindcss.com/docs/order): `classname=&apos;order-#&apos;`
- order is a child element that defines the order elements appear in (row vs column for responsive design)

[FlexBox](https://css-tricks.com/snippets/css/a-guide-to-flexbox/)
 is a tool that is most appropriate for app components, and small-scale layouts.

[Grid layout](https://css-tricks.com/snippets/css/complete-guide-grid/)
 is intended for larger scale layouts. (And possibly data visualizations?)

[Display](https://tailwindcss.com/docs/display)
: Hide an element on mobile: `className=&apos;hidden md:flex&apos;`

## Margins &amp; Padding

[Margin](https://tailwindcss.com/docs/margin): The margin property controls the space outside an element, 
and the padding property controls the space inside an element.

## Sizing
[Height](https://tailwindcss.com/docs/height) : `h-{number}`, `h-px`

## Styled Components

```bash
yarn add styled-components gatsby-plugin-styled-components babel-plugin-styled-components
```

[Hamburger Menu with Gatsby and Styled Components](https://www.youtube.com/watch?v=6cb56Luubd4)

## Importing Fonts
[How to add a Google Font to your Gatsby Tailwind Project](https://www.itzami.com/blog/how-to-add-a-google-font-to-your-gatsby-tailwind-project)

**Font-Family** has several default values which will use the default font related to that value: `serif`, `sans-serif`, `monospace`, etc. You can also reference the font name directly.

{/* ![web safe fonts](./media/content/web_safe_fonts.png) */}

Reference [cssFontStack](cssfontstack.com) to research font adoption when choosing fonts.

## Styling Text

There are three main properties for text: size, weight (bold), &amp; style (italics). 

**Font-Style** has two similar values, italics as well as oblique.  In the purest (type designer) sense, an oblique is a roman font that has been skewed a certain number of degrees (8-12 degrees, usually). An italic is created by the type designer with specific characters (notably lowercase a) drawn differently to create a more calligraphic, as well as slanted version.

It&apos;s best to specify an italic only when you&apos;re sure that font has been designed with one, so make sure to import the italic version of the font. Some fonts were meant not to be italicized or obliqued... but people did anyway. Operating systems will, upon clicking the &apos;italic&apos; icon, skew the font and create an oblique on the fly. Not a pleasant sight.

**Line-Height** or &apos;leading&apos; is the white space between lines of text. For reading text on desktop devices, the ideal line height of around 1.5 to 1.6. It always depends on your typeface, and the shorter the line, the lower the line height can be, especially for headings.

**Letter-Spacing** or &apos;tracking&apos; is the white space between letters. 

**Text-Align** values include: `center`, `left`, `right`, &amp; `justify`. When using justify make sure to set a max width. The ideal line has a length of 60 to 80 characters.

**Text-Transform** with a value `&apos;capitalize&apos;` will Proper Case the text.

## MDX
[MDX](https://www.gatsbyjs.com/docs/glossary/mdx/)
: MDX makes it possible to include React components in your Gatsby blog posts and pages.
[MDXProvider](https://www.gatsbyjs.com/docs/how-to/routing/customizing-components/)

[Gatsby JS Course: Add Styles to Markdown](https://www.youtube.com/watch?v=zOYshXpGdv4)

[Customizing Markdown Components](https://www.gatsbyjs.com/docs/how-to/routing/customizing-components/)



</content:encoded></item><item><title><![CDATA[Understanding Git]]></title><description><![CDATA[A little Git goes a long way. You can get pretty deep into a development career with just . . .  ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/git</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/git</guid><pubDate>Mon, 09 May 2022 00:00:00 GMT</pubDate><content:encoded>&lt;br/&gt;
&lt;br/&gt;

A little Git goes a long way. You can get pretty deep into a development career with just the basics. This video on [Git Core Concepts](https://www.youtube.com/watch?v=uR6G2v_WsRA) is a good starting place.
I developed a workflow based on ten lines of Git code. I learned how to deal with merge conflicts but, if you organize your work well they don&apos;t come up.
&lt;br/&gt;

**To start:**

    - git status (make sure there isn&apos;t any uncommited code)
    - git checkout *your-development-branch-name*
    - git pull (make sure you are working off of the most up to date code)
    - clear (not needed but i like to keep my terminal clean)
    - git checkout -b *new-branch-name, ususally a task name*
&lt;br/&gt;

You are clear to code. When you are ready to make a commit,

    - git status (I always want to check)
    - git add .
    - git commit -m &quot;*Your commit description.*&quot;
&lt;br/&gt;

Commit often. I do lots of small commits and comment my process.
&lt;br/&gt;

**Then when I am done with the task:**

    - git push
    - git push --set-upstream origin (only needed on the first push for a new branch)
&lt;br/&gt;

 That&apos;s it. A crib sheet with those ten lines of code saw me through my entire development career up until . . . a couple of days ago. These are the basics. 
 &lt;br/&gt;

 From here forward is what i consider intermidiate Git. A couple of days ago i added four lines to my crib sheet:
 &lt;br/&gt;

 **F&apos;ing Up with Git**
    - git log --oneline
    - q (to exit)
    - git reset --hard _sha1-hash-listed-in-the-git-log_
&lt;br/&gt;

The sha1 hash identifies what step you want to go back to and resets the commit history as well as your local files.
This overwrites any local changes you havn&apos;t commited
It resets (clears out) the staging area and overwrites content in the working directory (local) to what it looked like at the point of the commit identified
Lastly, when you just want your remote to match what you have locally:
    - git push -f origin main
&lt;br/&gt;

**Questions**
**What is a git working tree? What is a commit graph?**
There are three logical areas in which we work with our files: the working tree, staging area, and git history. The working tree is our file system. When we add, delete, and edit files, we do that in the working tree. The git history is the commit graph or commit history. To commit a change made in the working tree, that change needs to be staged (moved to the staging area).
We can unstage a file using,  git reset head fileName
We can then restore the working tree file using, git checkout –fileName
&lt;br/&gt;

**What is the best practice for managing branches?**
Branches allow us to work on different versions of the sames files in parallel. Edits on one branch are independent of the other branches. We can have a production branch, a development branch, and a branch to address bug fixes.
The way git knows what branch we are on is a special pointer called head. HEAD points to a branch, not specifically to a commit. In Git speak, HEAD tells us what we have checked out.
Technically, a branch is just a pointer to a sha1 hash.
&lt;br/&gt;

**How do i keep track of where i am in the commit path? How do i keep track of what branch i have files in (main / gh-pages / source)?**
Checkout a branch. The working tree will be updated to reflect the files in that branch. you can lookt at the commit graph to see changes. 
You can also use git diff to compare differences between branches. 

- git log —all –decorate –oneline –graph 
- alias graph=’git log —all –decorate –oneline –graph’
- git diff

&lt;br/&gt;

- **What is the origin? And what is the master / main?**
- **Do they exist (coexist) in both the local and remote repository?**
- **Or is one origin and the other main, (IE Local is origin and remote is main)?**

- Origin is an alias for the pointer to a remote repository (ie. git@github.com:user/repository.git). Master and main are names given to the default branch of a repository.
Origin/master is a remote-tracking branch.  It tells us what the master branch looks like @ origin. Fetch returns just the commit log to check if there are changes. To bring those changes in we use merge. Git pull combines these two commands into one action.

    - git fetch origin
    - git merge origin/main
    - git pull
&lt;br/&gt;

Adding more context to origin-master, le can look at the command, git push origin master, which uploads files to the remote (origin) in the master branch. 
&lt;br/&gt;



**Git Resources**
- [How to Reset, Revert, &amp; Return to Previous States in Git](https://opensource.com/article/18/6/git-reset-revert-rebase-commands)
- [Git Core Concepts](https://www.youtube.com/watch?v=uR6G2v_WsRA)
- [Git Branches](https://www.youtube.com/watch?v=FyAAIHHClqI)  
- [Git Remotes](https://www.youtube.com/watch?v=Gg4bLk8cGNo)
- [Pro Git Book](https://git-scm.com/book/en/v2)
- [A Visual Git Reference](https://marklodato.github.io/visual-git-guide/index-en.html)</content:encoded></item><item><title><![CDATA[Building A Marketing Blog with React.js]]></title><description><![CDATA[This is the price of experiance. I'm learning to use Gatsby. It's been two weeks. I spend an hour or two every day working through it. This is a list of resources i used to build my first Gatsby static site blog. ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/building-a-marketing-blog-with-react</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/building-a-marketing-blog-with-react</guid><pubDate>Fri, 29 Apr 2022 00:00:00 GMT</pubDate><content:encoded>

I&apos;m learning to use Gatsby. It&apos;s been two weeks. I spend an hour or two every day working through it. I spent a week refreshing myself with JavaScript and learning react.
I&apos;ve learned I don&apos;t want to  use react for traditional websites, marketing sites, blogs, etc. It doesn&apos;t do well with SEO. 
So i spend a few days going back and forth deciding between two frameworks that sit on top of react to build static sites: Gatsby VS Next.js.

Originally, I wanted to build the site with Jekyll. Reading up on Jekyll, I realize i don&apos;t want the added complexity of adding Ruby to my stack.
I do want to publish to Github Pages. I do want to create blog posts using markdown. Ideally, i want to do those two things in a react native framework.
As luck has it, good and bad, i have choices. Ultimately, i land on Gatsby. A lot of people like Next.js. I might regret this choice. That is the price of experience.
I like Gatsby overall, but what put it over the top is that it has a native data layer that I believe will meet my needs better.
&lt;br/&gt;

I started with the [Gastby Tutorial Walkthru](https://www.gatsbyjs.com/docs/tutorial/) as a starting point to build out my blog. This is the finished product.
&lt;hr/&gt;

![Blog Screen Shot](./media/content/blog_screen_shot.png) 

&lt;hr/&gt;

Every tutorial on working with dynamic Images in Gatsby uses a blog post page as a demo. These examples only use one image per post. 
I need to include multiple images on my index page. These have to be dynamic, one for each post. 
I read through the documentation but ultimatly it is the JavaScript that i was caught on.

I need to learn a CSS tool. I land on Tailwind. Mostly because my friend uses it. I get caught on FlexBox so i spend some more time learning it.
[![Gatsby &amp; TailwindCSS](https://img.youtube.com/vi/UBOj6rqRUME/hqdefault.jpg)](https://youtu.be/UBOj6rqRUME)

For my troubles i come across Post CSS. That is something to look into later.

I&apos;m done with version one. I still need to publish my site to Github Pages, but I will save that for another post that focuses on [Git &amp; Github](https://rho-lall.github.io/thoughts/git).

**Resources:**  
- [Gastby Tutorial Walkthru](https://www.gatsbyjs.com/docs/tutorial/)
- [Gatsby Plugin Image](https://www.gatsbyjs.com/plugins/gatsby-plugin-image/#dynamic-images)
- [An Intro to Gatsby Plugin Image](https://robertmarshall.dev/blog/an-introduction-to-gatsby-plugin-image/#how-to-use-gatsby-image)
- [Working with Images in Markdown](https://www.gatsbyjs.com/docs/working-with-images-in-markdown/)
- [Gatsby &amp; TailwindCSS](https://www.youtube.com/watch?v=Ej0tA_aSJ2k&amp;t=634s)
- [Tailwind CSS CrashCourse](https://www.youtube.com/watch?v=UBOj6rqRUME)
- [Post CSS](https://postcss.org/)
- [A Complete Guide to FlexBox](https://css-tricks.com/snippets/css/a-guide-to-flexbox/)
- [Publishing to Github Pages](https://www.gatsbyjs.com/docs/how-to/previews-deploys-hosting/how-gatsby-works-with-github-pages/)
</content:encoded></item><item><title><![CDATA[Markdown Example]]></title><description><![CDATA[ Notes on using Markdown that I find useful and want to keep handy.  ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/markdown</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/markdown</guid><pubDate>Sat, 01 Jan 2022 00:00:00 GMT</pubDate><content:encoded>## Video Link
[![Gatsby &amp; TailwindCSS](https://img.youtube.com/vi/UBOj6rqRUME/hqdefault.jpg)](https://youtu.be/UBOj6rqRUME)


## Image
![Covey 2x22 Matrix](./media/content/covey_2x2_matrix.png)

## Internal link
[tithing. Should you pay on your gross or net income?](/thoughts/tithing-should-you-pay-on-your-gross-or-net-income)

# H1
## H2
### H3

#### H4
##### H5
###### H6

list 
- one
- two
- three

`writting out some code`

&gt;Test Quote
&gt;this is a quote

&gt; ~ rho






</content:encoded></item><item><title><![CDATA[A Python Murder Mystery]]></title><description><![CDATA[
Coding up a script that uses natural language processing techniques (NLP) to analyse letters to find a killer.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/python-murder-mystery</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/python-murder-mystery</guid><pubDate>Mon, 30 Jul 2018 00:00:00 GMT</pubDate><content:encoded>## Jay Stacksby is dead.

Murdered on his isolated personal island, Jay Stacksby, billionaire and reality T.V. star, is dead. He was found just before the filming of the season finale of his smash hit A Brand New Jay. One of the three contestants is the killer, but local authorities can&apos;t figure out who.

After an eventful season of A Brand New Jay - Season 8, the 3 final contestants were invited to Jay Stacksby&apos;s private island to film the last three episodes. On the day of the finale Mr. Stacksby was found with one of his Professional Series 8-inch Chef Knives plunged through his heart!

According to the initial investigation, the film crew all live in a separate house on the other side of the island. Only the contestants were near enough to Stacksby to commit the crime. The murder left a note at the scene of the crime:

## The note.

&gt; You may call me heartless, a killer, a monster, a murderer, but I&apos;m still NOTHING compared to the villian that Jay was. This whole contest was a sham, an elaborate plot to shame the contestants and feed Jay&apos;s massive, massive ego. SURE you think you know him! You&apos;ve seen him smiling for the cameras, laughing, joking, telling stories, waving his money around like a prop but off camera he was a sinister beast, a cruel cruel taskmaster, he treated all of us like slaves, like cattle, like animals! Do you remember Lindsay, she was the first to go, he called her such horrible things that she cried all night, keeping up all up, crying, crying, and more crying, he broke her with his words. I miss my former cast members, all of them very much. And we had to live with him, live in his home, live in his power, deal with his crazy demands. AND FOR WHAT! DID YOU KNOW THAT THE PRIZE ISN&apos;T REAL? He never intended to marry one of us! The carrot on the stick was gone, all that was left was stick, he told us last night that we were all a terrible terrible disappointment and none of us would ever amount to anything, and that regardless of who won the contest he would never speak to any of us again! It&apos;s definitely the things like this you can feel in your gut how wrong he is! Well I showed him, he got what he deserved all right, I showed him, I showed him the person I am! I wasn&apos;t going to be pushed around any longer, and I wasn&apos;t going to let him go on pretending that he was some saint when all he was was a sick sick twisted man who deserved every bit of what he got. The fans need to know, Jay Stacksby is a vile amalgamation of all things evil and bad and the world is a better place without him. ~ The killer

Pretty sinister stuff! In addition to this bold-faced admission, we have the introduction letters of the three contestants. Maybe there is a way to use this information to determine who the author of this murder letter is?

## The Suspects

&gt; Salutations. My name? Myrtle. Myrtle Beech. I am a woman of simple tastes. I enjoy reading, thinking, and doing my taxes. I entered this competition because I want a serious relationship. I want a commitment. The last man I dated was too whimsical. He wanted to go on dates that had no plan. No end goal. Sometimes we would just end up wandering the streets after dinner. He called it a &quot;walk&quot;. A &quot;walk&quot; with no destination. Can you imagine? I like every action I take to have a measurable effect. When I see a movie, I like to walk away with insights that I did not have before. When I take a bike ride, there better be a worthy destination at the end of the bike path. Jay seems frivolous at times. This worries me. However, it is my staunch belief that one does not make and keep money without having a modicum of discipline. As such, I am hopeful. I will now list three things I cannot live without. Water. Emery boards. Dogs. Thank you for the opportunity to introduce myself. I look forward to the competition. ~ Myrtle Beech

&gt; Hi, I&apos;m Lily Trebuchet from East Egg, Long Island. I love cats, hiking, and curling up under a warm blanket with a book. So they gave this little questionnaire to use for our bios so lets get started. What are some of my least favorite household chores? Dishes, oh yes it&apos;s definitely the dishes, I just hate doing them, don&apos;t you? Who is your favorite actor and why? Hmm, that&apos;s a hard one, but I think recently I&apos;ll have to go with Michael B. Jordan, every bit of that man is handsome, HANDSOME! Do you remember seeing him shirtless? I can&apos;t believe what he does for the cameras! Okay okay next question, what is your perfect date? Well it starts with a nice dinner at a delicious but small restaurant, you know like one of those places where the owner is in the back and comes out to talk to you and ask you how your meal was. My favorite form of art? Another hard one, but I think I&apos;ll have to go with music, music you can feel in your whole body and it is electrifying and best of all, you can dance to it! Okay final question, let&apos;s see, What are three things you cannot live without? Well first off, my beautiful, beautiful cat Jerry, he is my heart and spirit animal. Second is pasta, definitely pasta, and the third I think is my family, I love all of them very much and they support me in everything I do. I know Jay Stacksby is a handsome man and all of us want to be the first to walk down the aisle with him, but I think he might truly be the one for me. Okay that&apos;s it for the bio, I hope you have fun watching the show! ~ Lily Trebuchet

&gt; A most good day to you all, I am Gregg T Fishy, of the Fishy Enterprise fortune. I am 37 years young, an adventurous spirit and I&apos;ve never lost my sense of childlike wonder. I do love to be in the backyard gardening and I have the most extraordinary time when I&apos;m fishing. Fishing for what, you might find yourself asking? Why, I happen to always be fishing for compliments of course! I have a stunning pair of radiant blue eyes that will pierce the soul of anyone who dare gaze upon my countenance. I quite enjoy going on long jaunts through garden paths and short walks through greenhouses. I hope that Jay will be as absolutely interesting as he appears on the television, I find that he has some of the most curious tastes in style and humor. When I&apos;m out and about I quite enjoy hearing tales that instill in my heart of hearts the fascination that beguiles my every day life, every fiber of my being scintillates and vascillates with extreme pleasure during one of these charming anecdotes and significantly pleases my beautiful personage. I cannot wait to enjoy being on the television program A Jay To Remember, it certainly seems like a grand time to explore life and love. ~ Gregg T. Fishy

## Can You Find the Killer?

This is my final project for my Codecademy Python class. I am coding up a script that uses natural language processing techniques (NLP) to analyse each letter and find out which contestant is the killer.

Before I started coding I read through each introduction and the murderer&apos;s note a few times. I think I have a pretty good idea of who the killer is. So I wrote down my guess and a short paragraph with my reasons why.

And now it&apos;s your turn! Follow [this link](https://docs.google.com/forms/d/e/1FAIpQLSeB0imzmz2-G03aA9iOZlhh4TnsUCTAFUQwG_UXrkFvlw3i-w/viewform) to a google poll and [tell me who you think the killer is](https://web.archive.org/web/20200120000854/https://docs.google.com/forms/d/e/1FAIpQLSeB0imzmz2-G03aA9iOZlhh4TnsUCTAFUQwG_UXrkFvlw3i-w/viewform?usp=sf_link). Stay tuned to find out who did it in an upcoming post.</content:encoded></item><item><title><![CDATA[Snowflake SQL: How do I exclude weekends between two dates in Snowflake SQL?]]></title><description><![CDATA[
Common ask in BI is to return the working days between two dates not the calendar days.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/snowflake-remove-weekends-from-date-range</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/snowflake-remove-weekends-from-date-range</guid><pubDate>Tue, 12 Jun 2018 00:00:00 GMT</pubDate><content:encoded>This post has been updated with additional content and a cleaner format. You can read the updated 2023 version here:

[Snowflake DateDiff Business Days](/thoughts/snowflake-datediff-business-days)[: How Do I Exclude Weekends?](/thoughts/snowflake-datediff-business-days)

### Original Post

`select`  
`DATEDIFF(&apos;day&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) + 1`  
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, DATEADD(&apos;day&apos;, 1, &apos;2022-07-14&apos;))`  
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) as working_days`  
`;`
    

`DATEDIFF(&apos;day&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) + 1`
`select`
`DATEDIFF(&apos;day&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) + 1`
          
This first expression naively counts days between start and end. 
The +1 means the end_date is included as part of the count.
          
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, DATEADD(&apos;day&apos;, 1, &apos;2022-07-14&apos;))`
        
This second expression counts Saturdays. 
Since there can never be fewer Saturdays than Sundays in a given range because 
Snowflake starts the week on Monday and Sunday is after Saturday, 
we will check whether the last day in the range is a Saturday.
This expression checks by calculating how many weeks there are in this range if the last day is forwarded by one day.
For example, if the last day is a Friday, then it moves to Saturday, and that partial week doesn&apos;t count towards our total 
because DATEDIFF(&apos;week&apos;, ...) only counts fully completed weeks. 
However, if the last day is a Saturday, then it gets bumped to a Sunday, and this count will increase.
        
`- DATEDIFF(&apos;week&apos;, &apos;2022-07-01&apos;, &apos;2022-07-14&apos;) as working_days`  
`;`

This third piece counts the number of fully completed weeks, which will be the same as the number of Sundays in that range
(there is one Sunday per week).

Putting all the expressions together, 
we subtract the Saturday count 
and Sunday count 
from the first naive count to calculate the number of weekdays elapsed in the time range.

This pattern can be adjusted to accommodate different week start days



### Resources:
[Snowflake DateDiff Business Days](/thoughts/snowflake-datediff-business-days): How Do I Exclude Weekends?  
https://docs.snowflake.com/en/sql-reference/functions-date-time.html#label-calendar-weeks-weekdays

</content:encoded></item><item><title><![CDATA[Tortoise IS The New Black]]></title><description><![CDATA[
Notes on using Tailwind CSS that I find useful and want to keep handy. 
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/tortoise-new-black</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/tortoise-new-black</guid><pubDate>Tue, 12 Jun 2018 00:00:00 GMT</pubDate><content:encoded>
I had the chance to dig into some data from Warby Parker as part of a combined project with Codecademy. 
I distilled data from several tables into a series of actionable insights about two of their marketing funnels. 
It was fun, for sure: “Any fool can complicate things. It takes genius to simplify them”, Albert Einstein.

A big takeaway from looking at the data is a preference for tortoise frames for both men and women. 
That preference was measurable in survey data as well as purchase data. 
When asked, women preferred tortoise to black with a 10% margin of error. 
Actual purchases confirmed this preference with a narrower margin of error, 5%.  Read here for [detail on my findings](https://www.slideshare.net/RhoLall/tortoise-is-the-new-black)
, and my [github repo](https://github.com/Rho-Lall/sql/tree/master/Warby%20Parker%20Codecademy%20-%20Tortoise%20IS%20The%20New%20Black).

Part of the project included a [code review from Codecademy](https://github.com/Rho-Lall/sql/issues/1). I am appreciative of the feedback. 
I often recommend Codecademy and have taken other courses from them as well.
</content:encoded></item><item><title><![CDATA[Data Warehousing for Dummies PDF: How BIG do I build?]]></title><description><![CDATA[
I want to talk about an important question, “Should you build one large database of information (a data warehouse) and then parcel off smaller portions to different organizations, or should you build a bunch of smaller scale databases (data marts) and then integrate them together later?
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/data-warehousing-for-dummies-pdf-how-big-do-i-build</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/data-warehousing-for-dummies-pdf-how-big-do-i-build</guid><pubDate>Wed, 25 Apr 2018 00:00:00 GMT</pubDate><content:encoded>This is the third blog in my Data Warehousing for Dummies blog series. If you would like, I have a FREE Data Warehousing for Dummies PDF that takes you through the whole process. Today, I want to talk about an important question, “Should you build one large database of information (a data warehouse) and then parcel off smaller portions to different organizations, or should you build a bunch of smaller scale databases (data marts) and then integrate them together later?”

If you say to yourself:

“Go big or go home. We are building a Costco size warehouse.” OR “ We want a data mart, not a warehouse.”

Then you are starting off on the wrong foot. It is easy to think in terms of big or small. It is better to think in terms of the answers you are looking for.

## Answers to Specific Business Questions

Often the answer to a handful of business questions drives an organization’s operations. Jim Rohn used to say, “There are always about a half dozen things that makes 80% of the difference in any area of your life.” Look for the few things that make the most difference, and spend the most of your time on those few things.

Business questions that carry this kind of weight are often analysed in Excel. 

&gt; “There are always about a half dozen things that makes 80% of the difference in any area of your life.” ~ Jim Rohn

The most democratic data analysis tool in use today is Excel. Virtually everyone has access to Excel. You may fire up Excel to consolidate and check the information you dig up in order to summarize and organize it. This type of “spread-mart” lacks the repeatability and data quality for anything more than a single serve analysis of one moment in time. Sounds like a job for a data warehouse!

For your first project, consider a small scale data mart designed specifically to answer these high impact, high value, “How are we doing?” type of questions.

## When A Data Warehouse is the better choice.

Until you understand the following three issues, you have no basis on deciding what investment to make:

The business problem you are trying to solve; the questions you are trying to answer.
The business value you expect to gain when your system is successfully built.
The volumes and characteristics of the data you need.

When considering the volume and characteristics of the data you need it can be helpful to think in terms of data sources. A small business can have anywhere from 8 to 10 sources, some examples: Quickbooks, Google Analytics, WordPress, Activecampaign, Amazon Affiliate Marketplace, Facebook, Twitter, Salesforce CRM, Survey Monkey, etc. Once you have asked your handful of questions, are the answers easier to get from one integrated database or a pair of independent databases?

A quick note on sources vs subject areas. In the last paragraph we listed out some data sources. An example of a subject area is “Marketing.” Marketing makes use of two data sources:Facebook and Google Analytics. A data mart can service one at most two subject areas. Most businesses have at least 5 subject areas: Marketing, Sales, Fulfilment, Customer Service, &amp; Finance. To address three or more subject areas requires a data warehouse.

## Business Intelligence Tools

Data Mart users usually ask questions with a “Tell me what happened” perspective. They require reports and don’t do much heavy analytical processing. On the other hand, there are a variety of different ways to look at the contents of a warehouses because it collects data on a broad range of subject areas:

Simple Reporting. Just like a data mart, the goal is “Tell me what happened?”
Business Analysis. Not just, “Tell me what happened?” but also, “Why?”
Dashboards &amp; ScoreCards. The warehouse gathers a variety of information and consolidates it: “Tell me a lot of things, but don’t make me work for it.”
Data Mining. In addition to, statistical analysis, econometrics, machine learning, AI, data mining is generally about taking large volumes of data and sifting through it to separate knowledge from the noise, often without even having to ask a specific question: “Tell me something interesting.”

Tool vendors increasingly try to provide suites of products to handle as many of these different functions as possible, you will need to deal with different products. Don’t assume that you can select a single vendor whose products satisfy all the business intelligence capabilities your users need. Carefully check out the vendors’ products - all of them.

## Benefits of a Data Mart

I started off asking about what kind on investment you should make in your data, to start. The answer depends on what key pieces of information you need to run your business. Once you know the answers you are looking for, then you can look at the data you have to go about getting those answers. Data marts are preferable to warehouses for three reasons:

Speed. These are typically completed in 90 to 120 days. Full scale warehouses take considerably longer.
Cost. Simple is fast. Fast is cheaper.
Risk. When you work with less data, fewer sources, over a shorter period of time you have a less complex environment - fewer associated risks.

In reality most “real” data investments involve a warehouse that covers all five subject areas I listed before: Marketing, Sales, Fulfillment, Customer Service, &amp; Finance. To lean more about how to build your first data warehouse check out this free resource: Data Warehousing For Dummies PDF.


</content:encoded></item><item><title><![CDATA[Data Warehousing for Dummies PDF: What is a data warehouse?]]></title><description><![CDATA[
This week I wanted to get into a little more about what a data warehouse is.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/data-warehousing-for-dummies-pdf-what-is-a-data-warehouse</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/data-warehousing-for-dummies-pdf-what-is-a-data-warehouse</guid><pubDate>Wed, 18 Apr 2018 00:00:00 GMT</pubDate><content:encoded>If you haven&apos;t already, you should check out my “data warehousing for dummies PDF”. Last week I started a new series on this blog exploring big data solutions for small business. My first step is creating a data warehouse. This week I wanted to get into a little more about what a data warehouse is.

As I am building out and iterating my own data warehousing for dummies PDF, I am reading the official for Dummies book and I don’t recommend it. It is written for an audience working in a larger organization, not a small business. For example it says, “You can’t easily find an organization right now that doesn’t have at least one data warehousing initiative underway, on the drawing board, or in production. Everyone wants to consume data - which leads directly to the need for a data warehouse!”  Meh.

I don’t think data drives a lot of activity in a small business (But we are trying to change that, right?).

## What Is a Data Warehouse?

Before I started reading up on it I thought of a data warehouse as a sort of central core, like a nucleus of a cell. It’s more like a Costco. A Costco . . . for data. If you ask 100 consultants to, “Define a data warehouse in 20 words or less.” 95 of them will drop jargon like, subject-oriented, time-variant, &amp; read-only. The other five are MBA’s that will talk about “improving corporate data driven decision making through timely access to information.

A data warehouse is a home for high value data. This is high quality, refined information that has gone through a 25 point quality inspection and an upsell for a warranty you don’t really need.

## What data should you stock?

A data warehouse is a retail store. But this store has shelves stocked with data. Not raw data. Not partially processes data. This data is clean, refined, packaged and marketed for use. It’s helpful to think of data as having three major categories:

- Run the business (raw) data: customer orders, manage finances, this is raw material.
- Integrate the business (intermediate) data: a master list of customers, or other tools built to improve the quality and sync two or more corporate apps
- Monitor the business (retail) data: Used for reporting and decision supports, like a financial dashboard. Data is clean to enable users to understand progress and evaluate cause and effect relationships.

Data assets are made of raw material (run the business data) to produce higher quality data products to integrate and monitor the business.

## How to manufacture data assets?

Data warehousing is the coordinated, architected, and periodic copying of data from various sources, both inside and outside the enterprise, into an environment optimized for analytical and informational processing. It generally follows these five steps:

- Select a focus area for tracking and reporting.
- Identify a group of business users as subject matter experts.
- List the different types of information that can enable them to use the data warehouse.
- Identify where to get this information.
- The data warehouse team creates extraction programs to collect the data, ETL (extract, transform, load).

## First Steps?

This is where the official for Dummies book really falls apart. It’s good reference material but doesn’t offer anything upfront to help you get started. The first major decision you are going to need to make is where are you going to build your data warehouse? The three leading options are:

- AWS
- Google Cloud
- Microsoft Azure

But you have options of using other platforms that work with the big three. Qubole is one. In my data warehousing for dummies pdf, I’ll help you take this first step as well as those that follow.</content:encoded></item><item><title><![CDATA[BIG DATA Solutions with Small Business Roots]]></title><description><![CDATA[
I just finished, Creating A Data Driven Enterprise With DataOps from Qubole. I was reading for big data solutions for small business and it came up short. It boasted a clearly tech oriented author, with bonafides from Facebook’s own data lake ]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/data-warehousing-for-dummies-pdf-big-data-solutions-with-small-business-roots</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/data-warehousing-for-dummies-pdf-big-data-solutions-with-small-business-roots</guid><pubDate>Wed, 11 Apr 2018 00:00:00 GMT</pubDate><content:encoded>I just finished, Creating A Data Driven Enterprise With DataOps from Qubole. I was reading for big data solutions for small business and it came up short. It boasted a clearly tech oriented author, with bonafides from Facebook’s own data lake. And offers insight into how LinkedIn, Twitter, &amp; Ebay got started with big data. What isn’t clear is if Qubole&apos;s strategy is to overwhelm and scare potential customers into just giving up and calling the “expert” for help with big data solutions. I’ll give them the benefit of the doubt and say they are clearly reaching for a tech audience. When I finished it, I had two main takeaways:

- The title of the book should have been, “How to Invest In Your Data.”
- I need to build a data warehouse before I can build a data lake.

I want to build a small business data lake. That would be fun. What does that mean? To start I want to connect to the APIs of the various social networks I am on and take my social media marketing to the next level. I’ve done that on a smaller scale and I learned that there are some insights you just can’t get any other way, even if you hire a full time social media manager. There is also the Google Analytics on my blog, I know there is more I can be doing with the data Google Analytics gives me. You can get lost in bells and whistles; to prioritize big data solutions for small business, I&apos;d start with a data warehouse.  

Probably not the best time to announce I am working on that with all that is happening with Facebook.

Oh. well.

For a small business, a blogger (like myself), or a starving artist social media offers the highest leverage to get your message out there. But it is really noisy. It’s also your best avenue to finding potential customers, but it is really noisy. But it&apos;s cheap, which is why it&apos;s so noisy. I think you can spend a lot of time wading through the noise on social media. I’m betting that my investment in a data warehouse/lake will help me get past the noise.

Which brings me back to the first takeaway, the title should have been, &quot;How To Invest In Your Data.&quot; That is how an owner thinks about big data solutions for small business: &quot;I know I should invest in data&quot;, she says,  &quot;I just don&apos;t know where to start.&quot; 

I&apos;ve been steeped in that grass roots approach thinking because I grew up in a small business, a New York Deli. (And yes, above is a pic of my family in the Deli.) I never watched Saturday morning cartoons growing up because we spent Saturdays at the Deli. It was my second home.

## BIG DATA Solutions for Small Business.

So . .. if you (1) have something to offer, (2) want to market on social media, and (3) believe Google Analytics and data can help you be more effective then you should sign up for my new BETA Course: How to Invest in YOUR Data and get my Free Data Warehousing for Dummies PDF.</content:encoded></item><item><title><![CDATA[Agile User Story]]></title><description><![CDATA[
User Story: As an analyst, I need the ability to communicate susinctly, so I can translate business needs into technical requirements.
]]></description><link>https://assumewisely.com/thoughts/analytics-engineering/agile-user-story</link><guid isPermaLink="false">https://assumewisely.com/thoughts/analytics-engineering/agile-user-story</guid><pubDate>Thu, 04 Jun 2015 00:00:00 GMT</pubDate><content:encoded>This is a template works well for development tasks as well as general business workflows. It&apos;s great for drafting requirements. I reference it all the time.
&lt;br/&gt;

User Story: As a [....User Role, such as Property Manager, etc....], I need the ability to [.....action / workflow needed.....], so I can [....benefit this feature will add....]
&lt;br/&gt;

Example: As a Property Manager, I need the ability to flag a lease as non-renewable so that I can easily keep track of which leases we don&apos;t want to offer renewals to.
&lt;br/&gt;

As an analyst, I need the ability to communicate susinctly, so I can translate business needs into technical requirements.

</content:encoded></item></channel></rss>